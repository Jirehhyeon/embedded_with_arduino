# ì‹ ê²½ë§ ë° ë¨¸ì‹ ëŸ¬ë‹ ì‹œìŠ¤í…œ ğŸ§ 

## ê°œìš”
Arduinoë¥¼ ì´ìš©í•˜ì—¬ ì‹ ê²½ë§ê³¼ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„í•˜ê³  í•™ìŠµí•˜ëŠ” ì™„ì „ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ëª©ì°¨
1. [ì‹ ê²½ë§ ê¸°ì´ˆ](#ì‹ ê²½ë§-ê¸°ì´ˆ)
2. [í¼ì…‰íŠ¸ë¡  êµ¬í˜„](#í¼ì…‰íŠ¸ë¡ -êµ¬í˜„)
3. [ë‹¤ì¸µ ì‹ ê²½ë§](#ë‹¤ì¸µ-ì‹ ê²½ë§)
4. [ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜](#ì—­ì „íŒŒ-ì•Œê³ ë¦¬ì¦˜)
5. [í•©ì„±ê³± ì‹ ê²½ë§(CNN)](#í•©ì„±ê³±-ì‹ ê²½ë§cnn)
6. [ìˆœí™˜ ì‹ ê²½ë§(RNN)](#ìˆœí™˜-ì‹ ê²½ë§rnn)
7. [ê°•í™”í•™ìŠµ ì‹œìŠ¤í…œ](#ê°•í™”í•™ìŠµ-ì‹œìŠ¤í…œ)
8. [ìì—°ì–´ ì²˜ë¦¬](#ìì—°ì–´-ì²˜ë¦¬)
9. [ì»´í“¨í„° ë¹„ì „](#ì»´í“¨í„°-ë¹„ì „)
10. [í†µí•© AI ì‹œìŠ¤í…œ](#í†µí•©-ai-ì‹œìŠ¤í…œ)

---

## ì‹ ê²½ë§ ê¸°ì´ˆ

### ë‰´ëŸ° ëª¨ë¸ê³¼ í™œì„±í™” í•¨ìˆ˜
```cpp
// ì‹ ê²½ë§ ê¸°ì´ˆ êµ¬ì¡° ë° ìˆ˜í•™ì  ëª¨ë¸
#include <math.h>
#include <EEPROM.h>

class NeuralNetworkLab {
private:
    // í™œì„±í™” í•¨ìˆ˜ íƒ€ì…
    enum ActivationType {
        SIGMOID = 0,
        TANH = 1,
        RELU = 2,
        LEAKY_RELU = 3,
        SOFTMAX = 4,
        LINEAR = 5
    };
    
    // ì‹ ê²½ë§ êµ¬ì¡°
    struct NetworkStructure {
        int input_size;
        int hidden_layers;
        int hidden_sizes[5];     // ìµœëŒ€ 5ê°œ ì€ë‹‰ì¸µ
        int output_size;
        ActivationType hidden_activation;
        ActivationType output_activation;
        float learning_rate;
        float momentum;
        float dropout_rate;
        bool use_bias;
    };
    
    // ë‰´ëŸ° í´ë˜ìŠ¤
    class Neuron {
    private:
        float weights[20];       // ìµœëŒ€ 20ê°œ ì…ë ¥
        float bias;
        float last_output;
        float gradient;
        int input_count;
        ActivationType activation;
        
    public:
        Neuron(int inputs, ActivationType act = SIGMOID) 
            : input_count(inputs), activation(act), bias(0), last_output(0), gradient(0) {
            // ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (Xavier ì´ˆê¸°í™”)
            float limit = sqrt(6.0 / (inputs + 1));
            for (int i = 0; i < input_count; i++) {
                weights[i] = random(-1000, 1000) * limit / 1000.0;
            }
            bias = random(-100, 100) / 1000.0;
        }
        
        float forward(float* inputs) {
            // ê°€ì¤‘í•© ê³„ì‚°
            float sum = bias;
            for (int i = 0; i < input_count; i++) {
                sum += weights[i] * inputs[i];
            }
            
            // í™œì„±í™” í•¨ìˆ˜ ì ìš©
            last_output = applyActivation(sum);
            return last_output;
        }
        
        void backward(float error, float* inputs, float learning_rate) {
            // ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
            gradient = error * activationDerivative(last_output);
            
            // ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            for (int i = 0; i < input_count; i++) {
                weights[i] += learning_rate * gradient * inputs[i];
            }
            bias += learning_rate * gradient;
        }
        
        float getWeight(int index) { return weights[index]; }
        float getBias() { return bias; }
        float getGradient() { return gradient; }
        float getLastOutput() { return last_output; }
        
    private:
        float applyActivation(float x) {
            switch (activation) {
                case SIGMOID:
                    return 1.0 / (1.0 + exp(-x));
                case TANH:
                    return tanh(x);
                case RELU:
                    return max(0.0f, x);
                case LEAKY_RELU:
                    return x > 0 ? x : 0.01 * x;
                case LINEAR:
                    return x;
                default:
                    return 1.0 / (1.0 + exp(-x));
            }
        }
        
        float activationDerivative(float output) {
            switch (activation) {
                case SIGMOID:
                    return output * (1.0 - output);
                case TANH:
                    return 1.0 - output * output;
                case RELU:
                    return last_output > 0 ? 1.0 : 0.0;
                case LEAKY_RELU:
                    return last_output > 0 ? 1.0 : 0.01;
                case LINEAR:
                    return 1.0;
                default:
                    return output * (1.0 - output);
            }
        }
    };
    
    NetworkStructure network_config;
    uint32_t training_epochs;
    float training_loss;
    bool is_training;
    
public:
    void initialize() {
        Serial.begin(115200);
        
        Serial.println("=== ì‹ ê²½ë§ ë° ë¨¸ì‹ ëŸ¬ë‹ ì—°êµ¬ì†Œ ===");
        Serial.println("Arduino ê¸°ë°˜ ë”¥ëŸ¬ë‹ êµìœ¡ ì‹œìŠ¤í…œ");
        Serial.println("ì§€ì› ê¸°ëŠ¥:");
        Serial.println("- ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  (MLP)");
        Serial.println("- ì—­ì „íŒŒ í•™ìŠµ");
        Serial.println("- ë‹¤ì–‘í•œ í™œì„±í™” í•¨ìˆ˜");
        Serial.println("- ì‹¤ì‹œê°„ í•™ìŠµ ëª¨ë‹ˆí„°ë§");
        Serial.println("- ëª¨ë¸ ì €ì¥/ë¡œë“œ");
        Serial.println();
        
        // ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ êµ¬ì„±
        setupDefaultNetwork();
        
        training_epochs = 0;
        training_loss = 0.0;
        is_training = false;
        
        Serial.println("ì‹ ê²½ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ");
        demonstrateActivationFunctions();
    }
    
    void setupDefaultNetwork() {
        // ê¸°ë³¸ XOR ë¬¸ì œ í•´ê²°ìš© ë„¤íŠ¸ì›Œí¬
        network_config.input_size = 2;
        network_config.hidden_layers = 1;
        network_config.hidden_sizes[0] = 4;
        network_config.output_size = 1;
        network_config.hidden_activation = SIGMOID;
        network_config.output_activation = SIGMOID;
        network_config.learning_rate = 0.1;
        network_config.momentum = 0.9;
        network_config.dropout_rate = 0.0;
        network_config.use_bias = true;
        
        Serial.println("ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ êµ¬ì„±:");
        Serial.print("ì…ë ¥ì¸µ: "); Serial.println(network_config.input_size);
        Serial.print("ì€ë‹‰ì¸µ: "); Serial.print(network_config.hidden_layers); 
        Serial.print("ê°œ ("); Serial.print(network_config.hidden_sizes[0]); Serial.println("ë‰´ëŸ°)");
        Serial.print("ì¶œë ¥ì¸µ: "); Serial.println(network_config.output_size);
        Serial.print("í•™ìŠµë¥ : "); Serial.println(network_config.learning_rate);
    }
    
    void demonstrateActivationFunctions() {
        Serial.println("\n=== í™œì„±í™” í•¨ìˆ˜ ì‹œì—° ===");
        
        float test_inputs[] = {-3, -1, 0, 1, 3};
        int num_inputs = 5;
        
        Serial.println("ì…ë ¥ê°’\tSigmoid\tTanh\tReLU\tLeakyReLU");
        Serial.println("-----------------------------------------------");
        
        for (int i = 0; i < num_inputs; i++) {
            float x = test_inputs[i];
            
            Serial.print(x, 1); Serial.print("\t");
            Serial.print(sigmoid(x), 3); Serial.print("\t");
            Serial.print(tanh(x), 3); Serial.print("\t");
            Serial.print(relu(x), 3); Serial.print("\t");
            Serial.println(leakyRelu(x), 3);
        }
        Serial.println();
    }
    
private:
    float sigmoid(float x) { return 1.0 / (1.0 + exp(-x)); }
    float relu(float x) { return max(0.0f, x); }
    float leakyRelu(float x) { return x > 0 ? x : 0.01 * x; }
    
    void saveModel() {
        Serial.println("ëª¨ë¸ì„ EEPROMì— ì €ì¥ ì¤‘...");
        // EEPROMì— ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ì €ì¥
        Serial.println("ëª¨ë¸ ì €ì¥ ì™„ë£Œ");
    }
    
    void loadModel() {
        Serial.println("EEPROMì—ì„œ ëª¨ë¸ ë¡œë“œ ì¤‘...");
        // EEPROMì—ì„œ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ë¡œë“œ
        Serial.println("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ");
    }
};
```

---

## í¼ì…‰íŠ¸ë¡  êµ¬í˜„

### ë‹¨ì¸µ ë° ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ 
```cpp
class PerceptronSystem {
private:
    // ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ 
    class SinglePerceptron {
    private:
        float weights[10];
        float bias;
        int input_size;
        float learning_rate;
        int epoch_count;
        
    public:
        SinglePerceptron(int inputs, float lr = 0.1) 
            : input_size(inputs), learning_rate(lr), bias(0), epoch_count(0) {
            // ê°€ì¤‘ì¹˜ ëœë¤ ì´ˆê¸°í™”
            for (int i = 0; i < input_size; i++) {
                weights[i] = random(-100, 100) / 100.0;
            }
        }
        
        float predict(float* inputs) {
            float sum = bias;
            for (int i = 0; i < input_size; i++) {
                sum += weights[i] * inputs[i];
            }
            return (sum >= 0) ? 1.0 : 0.0;  // ê³„ë‹¨ í•¨ìˆ˜
        }
        
        void train(float* inputs, float target) {
            float prediction = predict(inputs);
            float error = target - prediction;
            
            // ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (ë¸íƒ€ ê·œì¹™)
            for (int i = 0; i < input_size; i++) {
                weights[i] += learning_rate * error * inputs[i];
            }
            bias += learning_rate * error;
        }
        
        void trainEpoch(float training_data[][3], int data_size) {
            epoch_count++;
            float total_error = 0;
            
            for (int i = 0; i < data_size; i++) {
                float inputs[2] = {training_data[i][0], training_data[i][1]};
                float target = training_data[i][2];
                
                float prediction = predict(inputs);
                float error = target - prediction;
                total_error += abs(error);
                
                train(inputs, target);
            }
            
            Serial.print("ì—í¬í¬ "); Serial.print(epoch_count);
            Serial.print(" - ì´ ì˜¤ë¥˜: "); Serial.println(total_error);
        }
        
        void displayWeights() {
            Serial.print("ê°€ì¤‘ì¹˜: [");
            for (int i = 0; i < input_size; i++) {
                Serial.print(weights[i], 3);
                if (i < input_size - 1) Serial.print(", ");
            }
            Serial.print("], í¸í–¥: "); Serial.println(bias, 3);
        }
        
        void testPerformance(float test_data[][3], int test_size) {
            Serial.println("\n=== ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ===");
            int correct = 0;
            
            for (int i = 0; i < test_size; i++) {
                float inputs[2] = {test_data[i][0], test_data[i][1]};
                float target = test_data[i][2];
                float prediction = predict(inputs);
                
                Serial.print("ì…ë ¥: ["); Serial.print(inputs[0]); 
                Serial.print(", "); Serial.print(inputs[1]);
                Serial.print("] ì˜ˆì¸¡: "); Serial.print(prediction);
                Serial.print(" ì •ë‹µ: "); Serial.print(target);
                
                if (prediction == target) {
                    Serial.println(" âœ“");
                    correct++;
                } else {
                    Serial.println(" âœ—");
                }
            }
            
            float accuracy = (float)correct / test_size * 100;
            Serial.print("ì •í™•ë„: "); Serial.print(accuracy); Serial.println("%");
        }
    };
    
    // ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  (XOR ë¬¸ì œ í•´ê²°ìš©)
    class MultiLayerPerceptron {
    private:
        static const int INPUT_SIZE = 2;
        static const int HIDDEN_SIZE = 4;
        static const int OUTPUT_SIZE = 1;
        
        // ê°€ì¤‘ì¹˜ í–‰ë ¬
        float weights_input_hidden[INPUT_SIZE][HIDDEN_SIZE];
        float weights_hidden_output[HIDDEN_SIZE][OUTPUT_SIZE];
        float bias_hidden[HIDDEN_SIZE];
        float bias_output[OUTPUT_SIZE];
        
        // ë‰´ëŸ° ì¶œë ¥ê°’ (ìˆœì „íŒŒìš©)
        float hidden_output[HIDDEN_SIZE];
        float final_output[OUTPUT_SIZE];
        
        // í•™ìŠµ íŒŒë¼ë¯¸í„°
        float learning_rate;
        int training_epochs;
        
    public:
        MultiLayerPerceptron(float lr = 0.5) : learning_rate(lr), training_epochs(0) {
            initializeWeights();
        }
        
        void initializeWeights() {
            Serial.println("ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ì¤‘...");
            
            // ì…ë ¥-ì€ë‹‰ì¸µ ê°€ì¤‘ì¹˜
            for (int i = 0; i < INPUT_SIZE; i++) {
                for (int j = 0; j < HIDDEN_SIZE; j++) {
                    weights_input_hidden[i][j] = random(-1000, 1000) / 1000.0;
                }
            }
            
            // ì€ë‹‰-ì¶œë ¥ì¸µ ê°€ì¤‘ì¹˜
            for (int i = 0; i < HIDDEN_SIZE; i++) {
                for (int j = 0; j < OUTPUT_SIZE; j++) {
                    weights_hidden_output[i][j] = random(-1000, 1000) / 1000.0;
                }
            }
            
            // í¸í–¥ ì´ˆê¸°í™”
            for (int i = 0; i < HIDDEN_SIZE; i++) {
                bias_hidden[i] = random(-100, 100) / 1000.0;
            }
            for (int i = 0; i < OUTPUT_SIZE; i++) {
                bias_output[i] = random(-100, 100) / 1000.0;
            }
            
            Serial.println("ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ì™„ë£Œ");
        }
        
        float sigmoid(float x) {
            return 1.0 / (1.0 + exp(-x));
        }
        
        float sigmoidDerivative(float x) {
            return x * (1.0 - x);
        }
        
        float* forward(float* inputs) {
            // ì…ë ¥ì¸µ â†’ ì€ë‹‰ì¸µ
            for (int j = 0; j < HIDDEN_SIZE; j++) {
                float sum = bias_hidden[j];
                for (int i = 0; i < INPUT_SIZE; i++) {
                    sum += inputs[i] * weights_input_hidden[i][j];
                }
                hidden_output[j] = sigmoid(sum);
            }
            
            // ì€ë‹‰ì¸µ â†’ ì¶œë ¥ì¸µ
            for (int j = 0; j < OUTPUT_SIZE; j++) {
                float sum = bias_output[j];
                for (int i = 0; i < HIDDEN_SIZE; i++) {
                    sum += hidden_output[i] * weights_hidden_output[i][j];
                }
                final_output[j] = sigmoid(sum);
            }
            
            return final_output;
        }
        
        void backward(float* inputs, float* targets) {
            // ì¶œë ¥ì¸µ ì˜¤ë¥˜ ê³„ì‚°
            float output_errors[OUTPUT_SIZE];
            for (int i = 0; i < OUTPUT_SIZE; i++) {
                output_errors[i] = (targets[i] - final_output[i]) * 
                                  sigmoidDerivative(final_output[i]);
            }
            
            // ì€ë‹‰ì¸µ ì˜¤ë¥˜ ê³„ì‚°
            float hidden_errors[HIDDEN_SIZE];
            for (int i = 0; i < HIDDEN_SIZE; i++) {
                float error = 0;
                for (int j = 0; j < OUTPUT_SIZE; j++) {
                    error += output_errors[j] * weights_hidden_output[i][j];
                }
                hidden_errors[i] = error * sigmoidDerivative(hidden_output[i]);
            }
            
            // ì€ë‹‰-ì¶œë ¥ì¸µ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            for (int i = 0; i < HIDDEN_SIZE; i++) {
                for (int j = 0; j < OUTPUT_SIZE; j++) {
                    weights_hidden_output[i][j] += learning_rate * 
                        output_errors[j] * hidden_output[i];
                }
            }
            
            // ì…ë ¥-ì€ë‹‰ì¸µ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
            for (int i = 0; i < INPUT_SIZE; i++) {
                for (int j = 0; j < HIDDEN_SIZE; j++) {
                    weights_input_hidden[i][j] += learning_rate * 
                        hidden_errors[j] * inputs[i];
                }
            }
            
            // í¸í–¥ ì—…ë°ì´íŠ¸
            for (int i = 0; i < HIDDEN_SIZE; i++) {
                bias_hidden[i] += learning_rate * hidden_errors[i];
            }
            for (int i = 0; i < OUTPUT_SIZE; i++) {
                bias_output[i] += learning_rate * output_errors[i];
            }
        }
        
        void train(float training_data[][3], int data_size, int epochs) {
            Serial.println("\n=== MLP í•™ìŠµ ì‹œì‘ ===");
            Serial.println("XOR ë¬¸ì œ í•´ê²° ì¤‘...");
            
            for (int epoch = 0; epoch < epochs; epoch++) {
                float total_loss = 0;
                
                for (int i = 0; i < data_size; i++) {
                    float inputs[2] = {training_data[i][0], training_data[i][1]};
                    float targets[1] = {training_data[i][2]};
                    
                    // ìˆœì „íŒŒ
                    float* prediction = forward(inputs);
                    
                    // ì†ì‹¤ ê³„ì‚°
                    float loss = 0.5 * pow(targets[0] - prediction[0], 2);
                    total_loss += loss;
                    
                    // ì—­ì „íŒŒ
                    backward(inputs, targets);
                }
                
                if (epoch % 100 == 0) {
                    Serial.print("ì—í¬í¬ "); Serial.print(epoch);
                    Serial.print(" - í‰ê·  ì†ì‹¤: "); 
                    Serial.println(total_loss / data_size, 6);
                }
            }
            
            training_epochs += epochs;
            Serial.println("í•™ìŠµ ì™„ë£Œ!");
        }
        
        void test(float test_data[][3], int test_size) {
            Serial.println("\n=== XOR í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===");
            
            for (int i = 0; i < test_size; i++) {
                float inputs[2] = {test_data[i][0], test_data[i][1]};
                float target = test_data[i][2];
                
                float* prediction = forward(inputs);
                
                Serial.print(int(inputs[0])); Serial.print(" XOR ");
                Serial.print(int(inputs[1])); Serial.print(" = ");
                Serial.print(prediction[0], 4); Serial.print(" (ëª©í‘œ: ");
                Serial.print(target); Serial.print(")");
                
                // ì„ê³„ê°’ 0.5ë¡œ ì´ì§„ ë¶„ë¥˜
                int predicted_class = prediction[0] > 0.5 ? 1 : 0;
                if (predicted_class == int(target)) {
                    Serial.println(" âœ“");
                } else {
                    Serial.println(" âœ—");
                }
            }
        }
        
        void visualizeNetwork() {
            Serial.println("\n=== ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° ì‹œê°í™” ===");
            Serial.println("ì…ë ¥ì¸µ (2) â†’ ì€ë‹‰ì¸µ (4) â†’ ì¶œë ¥ì¸µ (1)");
            Serial.println();
            
            Serial.println("ì…ë ¥-ì€ë‹‰ì¸µ ê°€ì¤‘ì¹˜:");
            for (int i = 0; i < INPUT_SIZE; i++) {
                Serial.print("ì…ë ¥ "); Serial.print(i); Serial.print(": [");
                for (int j = 0; j < HIDDEN_SIZE; j++) {
                    Serial.print(weights_input_hidden[i][j], 3);
                    if (j < HIDDEN_SIZE - 1) Serial.print(", ");
                }
                Serial.println("]");
            }
            
            Serial.println("\nì€ë‹‰-ì¶œë ¥ì¸µ ê°€ì¤‘ì¹˜:");
            for (int i = 0; i < HIDDEN_SIZE; i++) {
                Serial.print("ì€ë‹‰ "); Serial.print(i); Serial.print(": ");
                Serial.println(weights_hidden_output[i][0], 3);
            }
        }
    };
    
    SinglePerceptron* perceptron;
    MultiLayerPerceptron* mlp;
    
public:
    void initialize() {
        Serial.begin(115200);
        
        Serial.println("=== í¼ì…‰íŠ¸ë¡  ì‹œìŠ¤í…œ ===");
        Serial.println("1. ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡  (AND ê²Œì´íŠ¸)");
        Serial.println("2. ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  (XOR ê²Œì´íŠ¸)");
        Serial.println();
        
        // ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡  ì´ˆê¸°í™” (AND ê²Œì´íŠ¸ í•™ìŠµìš©)
        perceptron = new SinglePerceptron(2, 0.1);
        
        // ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ì´ˆê¸°í™” (XOR ê²Œì´íŠ¸ í•™ìŠµìš©)
        mlp = new MultiLayerPerceptron(0.5);
        
        Serial.println("í¼ì…‰íŠ¸ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ");
    }
    
    void demonstratePerceptrons() {
        // AND ê²Œì´íŠ¸ ë°ì´í„°
        float and_data[4][3] = {
            {0, 0, 0},
            {0, 1, 0},
            {1, 0, 0},
            {1, 1, 1}
        };
        
        // XOR ê²Œì´íŠ¸ ë°ì´í„°
        float xor_data[4][3] = {
            {0, 0, 0},
            {0, 1, 1},
            {1, 0, 1},
            {1, 1, 0}
        };
        
        // 1. ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ ìœ¼ë¡œ AND ê²Œì´íŠ¸ í•™ìŠµ
        Serial.println("=== ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ : AND ê²Œì´íŠ¸ í•™ìŠµ ===");
        
        for (int epoch = 0; epoch < 10; epoch++) {
            perceptron->trainEpoch(and_data, 4);
        }
        
        perceptron->displayWeights();
        perceptron->testPerformance(and_data, 4);
        
        // 2. ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ ìœ¼ë¡œ XOR ê²Œì´íŠ¸ í•™ìŠµ
        Serial.println("\n=== ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ : XOR ê²Œì´íŠ¸ í•™ìŠµ ===");
        
        mlp->train(xor_data, 4, 1000);
        mlp->test(xor_data, 4);
        mlp->visualizeNetwork();
        
        // 3. ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ ì˜ í•œê³„ ì‹œì—°
        Serial.println("\n=== ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ ì˜ í•œê³„ ===");
        Serial.println("XOR ë¬¸ì œë¥¼ ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ ìœ¼ë¡œ í•´ê²° ì‹œë„...");
        
        SinglePerceptron xor_perceptron(2, 0.1);
        for (int epoch = 0; epoch < 20; epoch++) {
            xor_perceptron.trainEpoch(xor_data, 4);
        }
        
        Serial.println("ê²°ê³¼: ì„ í˜• ë¶„ë¦¬ ë¶ˆê°€ëŠ¥í•œ ë¬¸ì œëŠ” í•´ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        xor_perceptron.testPerformance(xor_data, 4);
    }
    
    void update() {
        // ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš© ëª¨ë“œ
        if (Serial.available()) {
            String command = Serial.readString();
            command.trim();
            
            if (command == "demo") {
                demonstratePerceptrons();
            } else if (command == "and") {
                trainANDGate();
            } else if (command == "xor") {
                trainXORGate();
            } else if (command == "test") {
                interactiveTest();
            }
        }
    }
    
private:
    void trainANDGate() {
        Serial.println("AND ê²Œì´íŠ¸ ì¬í•™ìŠµ ì¤‘...");
        float and_data[4][3] = {{0,0,0}, {0,1,0}, {1,0,0}, {1,1,1}};
        
        delete perceptron;
        perceptron = new SinglePerceptron(2, 0.1);
        
        for (int epoch = 0; epoch < 10; epoch++) {
            perceptron->trainEpoch(and_data, 4);
        }
        
        perceptron->testPerformance(and_data, 4);
    }
    
    void trainXORGate() {
        Serial.println("XOR ê²Œì´íŠ¸ ì¬í•™ìŠµ ì¤‘...");
        float xor_data[4][3] = {{0,0,0}, {0,1,1}, {1,0,1}, {1,1,0}};
        
        delete mlp;
        mlp = new MultiLayerPerceptron(0.5);
        
        mlp->train(xor_data, 4, 1000);
        mlp->test(xor_data, 4);
    }
    
    void interactiveTest() {
        Serial.println("ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ëª¨ë“œ");
        Serial.println("ë‘ ê°œì˜ 0 ë˜ëŠ” 1ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 1,0):");
        
        while (!Serial.available()) {
            delay(100);
        }
        
        String input = Serial.readString();
        input.trim();
        
        int comma_pos = input.indexOf(',');
        if (comma_pos > 0) {
            float x1 = input.substring(0, comma_pos).toFloat();
            float x2 = input.substring(comma_pos + 1).toFloat();
            
            float inputs[2] = {x1, x2};
            
            // AND ê²Œì´íŠ¸ ì˜ˆì¸¡
            float and_result = perceptron->predict(inputs);
            
            // XOR ê²Œì´íŠ¸ ì˜ˆì¸¡
            float* xor_result = mlp->forward(inputs);
            
            Serial.print("ì…ë ¥: ["); Serial.print(x1); Serial.print(", "); 
            Serial.print(x2); Serial.println("]");
            Serial.print("AND ê²°ê³¼: "); Serial.println(and_result);
            Serial.print("XOR ê²°ê³¼: "); Serial.println(xor_result[0], 4);
        }
    }
};

PerceptronSystem perceptron_system;

void setup() {
    perceptron_system.initialize();
    
    Serial.println("\nëª…ë ¹ì–´:");
    Serial.println("'demo' - ì „ì²´ ì‹œì—°");
    Serial.println("'and' - AND ê²Œì´íŠ¸ í•™ìŠµ");
    Serial.println("'xor' - XOR ê²Œì´íŠ¸ í•™ìŠµ");
    Serial.println("'test' - ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸");
}

void loop() {
    perceptron_system.update();
    delay(100);
}
```

---

## ë‹¤ì¸µ ì‹ ê²½ë§

### ê¹Šì€ ì‹ ê²½ë§ êµ¬í˜„
```cpp
class DeepNeuralNetwork {
private:
    static const int MAX_LAYERS = 6;
    static const int MAX_NEURONS = 20;
    
    struct Layer {
        int neuron_count;
        float neurons[MAX_NEURONS];
        float biases[MAX_NEURONS];
        float weights[MAX_NEURONS][MAX_NEURONS];  // ì´ì „ ì¸µê³¼ì˜ ì—°ê²°
        float gradients[MAX_NEURONS];
        int activation_type;  // 0: sigmoid, 1: relu, 2: tanh
        
        Layer() : neuron_count(0), activation_type(0) {}
    };
    
    struct NetworkConfig {
        int layer_count;
        int layer_sizes[MAX_LAYERS];
        int activation_types[MAX_LAYERS];
        float learning_rate;
        float momentum;
        bool use_dropout;
        float dropout_rate;
        bool use_batch_norm;
    };
    
    Layer layers[MAX_LAYERS];
    NetworkConfig config;
    float training_loss;
    int training_epoch;
    bool is_trained;
    
    // ë“œë¡­ì•„ì›ƒìš© ë§ˆìŠ¤í¬
    bool dropout_mask[MAX_LAYERS][MAX_NEURONS];
    
public:
    DeepNeuralNetwork() {
        training_loss = 0.0;
        training_epoch = 0;
        is_trained = false;
        
        // ê¸°ë³¸ êµ¬ì„± (4ì¸µ ì‹ ê²½ë§)
        config.layer_count = 4;
        config.layer_sizes[0] = 4;   // ì…ë ¥ì¸µ
        config.layer_sizes[1] = 8;   // ì€ë‹‰ì¸µ 1
        config.layer_sizes[2] = 6;   // ì€ë‹‰ì¸µ 2
        config.layer_sizes[3] = 2;   // ì¶œë ¥ì¸µ
        
        config.activation_types[0] = 0; // ì…ë ¥ì¸µ (ì‚¬ì‹¤ìƒ ì‚¬ìš© ì•ˆí•¨)
        config.activation_types[1] = 1; // ReLU
        config.activation_types[2] = 1; // ReLU  
        config.activation_types[3] = 0; // Sigmoid
        
        config.learning_rate = 0.01;
        config.momentum = 0.9;
        config.use_dropout = true;
        config.dropout_rate = 0.2;
        config.use_batch_norm = false;
    }
    
    void initialize() {
        Serial.println("=== ê¹Šì€ ì‹ ê²½ë§ ì´ˆê¸°í™” ===");
        
        // ê° ì¸µ ì´ˆê¸°í™”
        for (int l = 0; l < config.layer_count; l++) {
            layers[l].neuron_count = config.layer_sizes[l];
            layers[l].activation_type = config.activation_types[l];
            
            Serial.print("ì¸µ "); Serial.print(l); Serial.print(": ");
            Serial.print(layers[l].neuron_count); Serial.print(" ë‰´ëŸ°");
            
            if (l > 0) {
                // ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (He ì´ˆê¸°í™”)
                float std_dev = sqrt(2.0 / config.layer_sizes[l-1]);
                
                for (int i = 0; i < layers[l].neuron_count; i++) {
                    for (int j = 0; j < layers[l-1].neuron_count; j++) {
                        layers[l].weights[i][j] = random(-1000, 1000) * std_dev / 1000.0;
                    }
                    layers[l].biases[i] = 0.0;  // í¸í–¥ì€ 0ìœ¼ë¡œ ì´ˆê¸°í™”
                }
                Serial.print(" (ê°€ì¤‘ì¹˜: "); Serial.print(layers[l-1].neuron_count);
                Serial.print(" Ã— "); Serial.print(layers[l].neuron_count); Serial.print(")");
            }
            
            Serial.println();
        }
        
        Serial.println("ê¹Šì€ ì‹ ê²½ë§ ì´ˆê¸°í™” ì™„ë£Œ");
        displayNetworkArchitecture();
    }
    
    void displayNetworkArchitecture() {
        Serial.println("\n=== ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° ===");
        Serial.println("ì…ë ¥ì¸µ â†’ ì€ë‹‰ì¸µ1 â†’ ì€ë‹‰ì¸µ2 â†’ ì¶œë ¥ì¸µ");
        
        for (int l = 0; l < config.layer_count; l++) {
            Serial.print("  "); Serial.print(layers[l].neuron_count);
            if (l < config.layer_count - 1) Serial.print(" â†’");
        }
        Serial.println();
        
        Serial.println("\ní™œì„±í™” í•¨ìˆ˜:");
        for (int l = 1; l < config.layer_count; l++) {
            Serial.print("ì¸µ "); Serial.print(l); Serial.print(": ");
            switch (layers[l].activation_type) {
                case 0: Serial.println("Sigmoid"); break;
                case 1: Serial.println("ReLU"); break;
                case 2: Serial.println("Tanh"); break;
            }
        }
        
        // ì´ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
        int total_params = 0;
        for (int l = 1; l < config.layer_count; l++) {
            int layer_params = layers[l].neuron_count * (layers[l-1].neuron_count + 1);
            total_params += layer_params;
        }
        
        Serial.print("ì´ íŒŒë¼ë¯¸í„° ìˆ˜: "); Serial.println(total_params);
    }
    
    float* forward(float* inputs, bool training_mode = false) {
        // ì…ë ¥ì¸µ ì„¤ì •
        for (int i = 0; i < layers[0].neuron_count; i++) {
            layers[0].neurons[i] = inputs[i];
        }
        
        // ìˆœì „íŒŒ
        for (int l = 1; l < config.layer_count; l++) {
            for (int i = 0; i < layers[l].neuron_count; i++) {
                float sum = layers[l].biases[i];
                
                // ê°€ì¤‘í•© ê³„ì‚°
                for (int j = 0; j < layers[l-1].neuron_count; j++) {
                    sum += layers[l-1].neurons[j] * layers[l].weights[i][j];
                }
                
                // í™œì„±í™” í•¨ìˆ˜ ì ìš©
                layers[l].neurons[i] = applyActivation(sum, layers[l].activation_type);
                
                // ë“œë¡­ì•„ì›ƒ ì ìš© (í•™ìŠµ ì‹œì—ë§Œ)
                if (training_mode && config.use_dropout && l < config.layer_count - 1) {
                    float dropout_prob = random(0, 1000) / 1000.0;
                    if (dropout_prob < config.dropout_rate) {
                        layers[l].neurons[i] = 0.0;
                        dropout_mask[l][i] = false;
                    } else {
                        dropout_mask[l][i] = true;
                        // ì¸ë²„í‹°ë“œ ë“œë¡­ì•„ì›ƒ
                        layers[l].neurons[i] /= (1.0 - config.dropout_rate);
                    }
                }
            }
        }
        
        return layers[config.layer_count - 1].neurons;
    }
    
    void backward(float* targets) {
        int output_layer = config.layer_count - 1;
        
        // ì¶œë ¥ì¸µ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
        for (int i = 0; i < layers[output_layer].neuron_count; i++) {
            float output = layers[output_layer].neurons[i];
            float error = targets[i] - output;
            layers[output_layer].gradients[i] = error * 
                activationDerivative(output, layers[output_layer].activation_type);
        }
        
        // ì€ë‹‰ì¸µ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° (ì—­ì „íŒŒ)
        for (int l = output_layer - 1; l >= 1; l--) {
            for (int i = 0; i < layers[l].neuron_count; i++) {
                float error = 0.0;
                
                // ë‹¤ìŒ ì¸µìœ¼ë¡œë¶€í„°ì˜ ì˜¤ë¥˜ ì—­ì „íŒŒ
                for (int j = 0; j < layers[l+1].neuron_count; j++) {
                    error += layers[l+1].gradients[j] * layers[l+1].weights[j][i];
                }
                
                layers[l].gradients[i] = error * 
                    activationDerivative(layers[l].neurons[i], layers[l].activation_type);
                
                // ë“œë¡­ì•„ì›ƒ ë§ˆìŠ¤í¬ ì ìš©
                if (config.use_dropout && !dropout_mask[l][i]) {
                    layers[l].gradients[i] = 0.0;
                }
            }
        }
        
        // ê°€ì¤‘ì¹˜ ë° í¸í–¥ ì—…ë°ì´íŠ¸
        for (int l = 1; l < config.layer_count; l++) {
            for (int i = 0; i < layers[l].neuron_count; i++) {
                // í¸í–¥ ì—…ë°ì´íŠ¸
                layers[l].biases[i] += config.learning_rate * layers[l].gradients[i];
                
                // ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
                for (int j = 0; j < layers[l-1].neuron_count; j++) {
                    layers[l].weights[i][j] += config.learning_rate * 
                        layers[l].gradients[i] * layers[l-1].neurons[j];
                }
            }
        }
    }
    
    void train(float training_data[][6], int data_size, int epochs) {
        Serial.println("\n=== ê¹Šì€ ì‹ ê²½ë§ í•™ìŠµ ì‹œì‘ ===");
        Serial.print("ë°ì´í„° í¬ê¸°: "); Serial.println(data_size);
        Serial.print("ì—í¬í¬: "); Serial.println(epochs);
        
        for (int epoch = 0; epoch < epochs; epoch++) {
            float epoch_loss = 0.0;
            
            for (int i = 0; i < data_size; i++) {
                // ì…ë ¥ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬ (4ê°œ ì…ë ¥, 2ê°œ ì¶œë ¥)
                float inputs[4] = {training_data[i][0], training_data[i][1], 
                                 training_data[i][2], training_data[i][3]};
                float targets[2] = {training_data[i][4], training_data[i][5]};
                
                // ìˆœì „íŒŒ
                float* outputs = forward(inputs, true);
                
                // ì†ì‹¤ ê³„ì‚° (í‰ê·  ì œê³± ì˜¤ì°¨)
                float loss = 0.0;
                for (int j = 0; j < 2; j++) {
                    float error = targets[j] - outputs[j];
                    loss += 0.5 * error * error;
                }
                epoch_loss += loss;
                
                // ì—­ì „íŒŒ
                backward(targets);
            }
            
            training_epoch++;
            training_loss = epoch_loss / data_size;
            
            if (epoch % 100 == 0 || epoch == epochs - 1) {
                Serial.print("ì—í¬í¬ "); Serial.print(epoch);
                Serial.print(" - í‰ê·  ì†ì‹¤: "); Serial.println(training_loss, 6);
            }
        }
        
        is_trained = true;
        Serial.println("í•™ìŠµ ì™„ë£Œ!");
    }
    
    void test(float test_data[][6], int test_size) {
        if (!is_trained) {
            Serial.println("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
            return;
        }
        
        Serial.println("\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===");
        float total_loss = 0.0;
        
        for (int i = 0; i < test_size; i++) {
            float inputs[4] = {test_data[i][0], test_data[i][1], 
                             test_data[i][2], test_data[i][3]};
            float targets[2] = {test_data[i][4], test_data[i][5]};
            
            float* outputs = forward(inputs, false);
            
            Serial.print("ì…ë ¥: [");
            for (int j = 0; j < 4; j++) {
                Serial.print(inputs[j], 2);
                if (j < 3) Serial.print(", ");
            }
            Serial.print("] â†’ ì¶œë ¥: [");
            for (int j = 0; j < 2; j++) {
                Serial.print(outputs[j], 4);
                if (j < 1) Serial.print(", ");
            }
            Serial.print("] (ëª©í‘œ: [");
            for (int j = 0; j < 2; j++) {
                Serial.print(targets[j], 2);
                if (j < 1) Serial.print(", ");
            }
            Serial.println("])");
            
            // ì†ì‹¤ ê³„ì‚°
            float loss = 0.0;
            for (int j = 0; j < 2; j++) {
                float error = targets[j] - outputs[j];
                loss += 0.5 * error * error;
            }
            total_loss += loss;
        }
        
        Serial.print("í‰ê·  í…ŒìŠ¤íŠ¸ ì†ì‹¤: "); Serial.println(total_loss / test_size, 6);
    }
    
    void analyzeNetwork() {
        Serial.println("\n=== ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ===");
        
        // ê°€ì¤‘ì¹˜ ë¶„í¬ ë¶„ì„
        for (int l = 1; l < config.layer_count; l++) {
            float min_weight = 999, max_weight = -999, avg_weight = 0;
            int weight_count = 0;
            
            for (int i = 0; i < layers[l].neuron_count; i++) {
                for (int j = 0; j < layers[l-1].neuron_count; j++) {
                    float w = layers[l].weights[i][j];
                    min_weight = min(min_weight, w);
                    max_weight = max(max_weight, w);
                    avg_weight += w;
                    weight_count++;
                }
            }
            
            avg_weight /= weight_count;
            
            Serial.print("ì¸µ "); Serial.print(l); Serial.print(" ê°€ì¤‘ì¹˜ - ");
            Serial.print("ìµœì†Œ: "); Serial.print(min_weight, 4);
            Serial.print(", ìµœëŒ€: "); Serial.print(max_weight, 4);
            Serial.print(", í‰ê· : "); Serial.println(avg_weight, 4);
        }
        
        // ë‰´ëŸ° í™œì„±í™” ë¶„ì„
        Serial.println("\ní˜„ì¬ ë‰´ëŸ° í™œì„±í™”:");
        for (int l = 0; l < config.layer_count; l++) {
            Serial.print("ì¸µ "); Serial.print(l); Serial.print(": [");
            for (int i = 0; i < layers[l].neuron_count; i++) {
                Serial.print(layers[l].neurons[i], 3);
                if (i < layers[l].neuron_count - 1) Serial.print(", ");
            }
            Serial.println("]");
        }
    }
    
private:
    float applyActivation(float x, int type) {
        switch (type) {
            case 0: // Sigmoid
                return 1.0 / (1.0 + exp(-x));
            case 1: // ReLU
                return max(0.0f, x);
            case 2: // Tanh
                return tanh(x);
            default:
                return x;
        }
    }
    
    float activationDerivative(float output, int type) {
        switch (type) {
            case 0: // Sigmoid
                return output * (1.0 - output);
            case 1: // ReLU
                return output > 0 ? 1.0 : 0.0;
            case 2: // Tanh
                return 1.0 - output * output;
            default:
                return 1.0;
        }
    }
};

// ì‚¬ìš© ì˜ˆì‹œ
DeepNeuralNetwork dnn;

void setup() {
    Serial.begin(115200);
    dnn.initialize();
    
    // ì˜ˆì‹œ ë°ì´í„° ìƒì„± (4ì…ë ¥ â†’ 2ì¶œë ¥)
    float training_data[8][6] = {
        {1, 0, 1, 0,  0.8, 0.2},
        {0, 1, 0, 1,  0.2, 0.8},
        {1, 1, 0, 0,  0.9, 0.1},
        {0, 0, 1, 1,  0.1, 0.9},
        {1, 0, 0, 1,  0.6, 0.4},
        {0, 1, 1, 0,  0.4, 0.6},
        {1, 1, 1, 0,  0.7, 0.3},
        {0, 0, 0, 1,  0.3, 0.7}
    };
    
    // í•™ìŠµ
    dnn.train(training_data, 8, 1000);
    
    // í…ŒìŠ¤íŠ¸
    dnn.test(training_data, 8);
    
    // ë„¤íŠ¸ì›Œí¬ ë¶„ì„
    dnn.analyzeNetwork();
}

void loop() {
    delay(1000);
}
```

ì´ì–´ì„œ ë‚˜ë¨¸ì§€ ì‹ ê²½ë§ ì‹œìŠ¤í…œë“¤ì„ ê³„ì† ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.